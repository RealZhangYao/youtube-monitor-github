#!/usr/bin/env python3
"""
ç›´æ¥æ¨¡æ‹Ÿæµè§ˆå™¨è¡Œä¸ºè·å–å­—å¹•
"""

import requests
import re
import json
import logging
import urllib.parse
import time
from bs4 import BeautifulSoup

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def simulate_full_browser_flow():
    """å®Œæ•´æ¨¡æ‹Ÿæµè§ˆå™¨è®¿é—® DownSub.com çš„æµç¨‹"""

    session = requests.Session()

    # è®¾ç½®å®Œæ•´çš„æµè§ˆå™¨å¤´éƒ¨
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7',
        'Accept-Encoding': 'gzip, deflate, br',
        'DNT': '1',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none',
        'Sec-Fetch-User': '?1',
        'Cache-Control': 'max-age=0'
    })

    # æˆ‘ä»¬çŸ¥é“æœ‰å­—å¹•çš„è§†é¢‘URL
    video_url = 'https://www.youtube.com/watch?v=zsTLDSibZnE'

    logger.info("ğŸŒ æ­¥éª¤ 1: è®¿é—® DownSub ä¸»é¡µ...")

    try:
        # æ­¥éª¤ 1: è®¿é—®ä¸»é¡µè·å–åˆå§‹çŠ¶æ€
        response = session.get('https://downsub.com', timeout=30)
        logger.info(f"ä¸»é¡µè®¿é—®: {response.status_code}")

        if response.status_code == 200:
            # ä¿å­˜ä¸»é¡µ HTML ç”¨äºåˆ†æ
            with open('downsub_homepage.html', 'w', encoding='utf-8') as f:
                f.write(response.text)

            # åˆ†æé¡µé¢ä¸­çš„ JavaScript å’Œè¡¨å•
            soup = BeautifulSoup(response.text, 'html.parser')

            # æŸ¥æ‰¾è¡¨å•
            forms = soup.find_all('form')
            logger.info(f"æ‰¾åˆ° {len(forms)} ä¸ªè¡¨å•")

            for i, form in enumerate(forms):
                action = form.get('action', '/')
                method = form.get('method', 'GET')
                logger.info(f"  è¡¨å• {i+1}: {method} {action}")

                # æŸ¥æ‰¾è¾“å…¥å­—æ®µ
                inputs = form.find_all('input')
                for inp in inputs:
                    name = inp.get('name', '')
                    type_attr = inp.get('type', '')
                    if name:
                        logger.info(f"    è¾“å…¥: {name} ({type_attr})")

    except Exception as e:
        logger.error(f"è®¿é—®ä¸»é¡µå¤±è´¥: {e}")
        return None

    logger.info("\nğŸ¯ æ­¥éª¤ 2: æ¨¡æ‹Ÿè¡¨å•æäº¤...")

    try:
        # æ­¥éª¤ 2: ä½¿ç”¨ä¸åŒçš„è¡¨å•æäº¤æ–¹å¼
        submit_methods = [
            # æ–¹æ³• 1: ç›´æ¥ URL å‚æ•°
            {
                'method': 'GET',
                'url': 'https://downsub.com',
                'params': {'url': video_url}
            },
            # æ–¹æ³• 2: POST è¡¨å•
            {
                'method': 'POST',
                'url': 'https://downsub.com',
                'data': {'url': video_url}
            },
            # æ–¹æ³• 3: ä¸åŒçš„å­—æ®µå
            {
                'method': 'POST',
                'url': 'https://downsub.com',
                'data': {'supported_sites': video_url, 'submit': 'Download'}
            }
        ]

        for i, method in enumerate(submit_methods, 1):
            logger.info(f"\nğŸ§ª å°è¯•æ–¹æ³• {i}: {method['method']}")

            session.headers.update({
                'Referer': 'https://downsub.com/',
                'Origin': 'https://downsub.com',
            })

            if method['method'] == 'GET':
                response = session.get(method['url'], params=method.get('params'), timeout=30)
            else:
                session.headers['Content-Type'] = 'application/x-www-form-urlencoded'
                response = session.post(method['url'], data=method.get('data'), timeout=30)

            logger.info(f"å“åº”: {response.status_code}, é•¿åº¦: {len(response.text)}")

            if response.status_code == 200:
                # ä¿å­˜å“åº”ç”¨äºåˆ†æ
                with open(f'downsub_response_method_{i}.html', 'w', encoding='utf-8') as f:
                    f.write(response.text)

                # æŸ¥æ‰¾å­—å¹•ä¸‹è½½é“¾æ¥
                subtitle_links = find_subtitle_links(response.text)
                if subtitle_links:
                    logger.info(f"âœ… æ–¹æ³• {i} æ‰¾åˆ° {len(subtitle_links)} ä¸ªå­—å¹•é“¾æ¥:")
                    for link in subtitle_links:
                        logger.info(f"  ğŸ”— {link}")
                        # å°è¯•ä¸‹è½½ç¬¬ä¸€ä¸ªé“¾æ¥
                        if download_subtitle_from_link(session, link):
                            return True

            time.sleep(2)  # é¿å…è¯·æ±‚è¿‡å¿«

    except Exception as e:
        logger.error(f"è¡¨å•æäº¤å¤±è´¥: {e}")

    logger.info("\nğŸ” æ­¥éª¤ 3: åˆ†æ AJAX è°ƒç”¨...")

    try:
        # æ­¥éª¤ 3: å°è¯• AJAX è°ƒç”¨
        session.headers.update({
            'Accept': 'application/json, text/plain, */*',
            'Content-Type': 'application/json',
            'X-Requested-With': 'XMLHttpRequest'
        })

        # ä½¿ç”¨å‘ç°çš„ API ç«¯ç‚¹
        api_response = session.post('https://get.downsub.com/', json={'url': video_url}, timeout=30)
        logger.info(f"API å“åº”: {api_response.status_code}")

        if api_response.status_code == 200:
            api_data = api_response.json()
            logger.info("API æ•°æ®:")
            logger.info(json.dumps(api_data, indent=2, ensure_ascii=False))

            # æŸ¥æ‰¾å¯èƒ½çš„å­—å¹•ä¿¡æ¯
            if api_data.get('subtitles') or api_data.get('subtitlesAutoTrans'):
                logger.info("âœ… API è¿”å›äº†å­—å¹•æ•°æ®")
                return api_data
            else:
                logger.info("âš ï¸ API å“åº”ä¸­æ²¡æœ‰å­—å¹•æ•°æ®")

    except Exception as e:
        logger.error(f"AJAX è°ƒç”¨å¤±è´¥: {e}")

    return None


def find_subtitle_links(html_content):
    """åœ¨ HTML å†…å®¹ä¸­æŸ¥æ‰¾å­—å¹•ä¸‹è½½é“¾æ¥"""

    links = []

    # å¤šç§æ¨¡å¼æŸ¥æ‰¾å­—å¹•é“¾æ¥
    patterns = [
        r'href=["\']([^"\']*download\.subtitle\.to[^"\']*)["\']',
        r'href=["\']([^"\']*\.(?:srt|vtt|txt|sbv)[^"\']*)["\']',
        r'href=["\']([^"\']*download[^"\']*subtitle[^"\']*)["\']',
        r'href=["\']([^"\']*subtitle[^"\']*download[^"\']*)["\']',
    ]

    for pattern in patterns:
        matches = re.findall(pattern, html_content, re.IGNORECASE)
        for match in matches:
            if match not in links:
                links.append(match)

    # ä¹ŸæŸ¥æ‰¾å¯èƒ½çš„ JavaScript ä¸­çš„é“¾æ¥
    js_patterns = [
        r'["\']([^"\']*download\.subtitle\.to[^"\']*)["\']',
        r'url\s*:\s*["\']([^"\']*download[^"\']*)["\']',
    ]

    for pattern in js_patterns:
        matches = re.findall(pattern, html_content, re.IGNORECASE)
        for match in matches:
            if 'download.subtitle.to' in match and match not in links:
                links.append(match)

    return links


def download_subtitle_from_link(session, link):
    """ä»ç»™å®šé“¾æ¥ä¸‹è½½å­—å¹•"""

    try:
        logger.info(f"ğŸ“¥ å°è¯•ä¸‹è½½: {link}")

        # ç¡®ä¿é“¾æ¥æ˜¯ç»å¯¹è·¯å¾„
        if link.startswith('/'):
            link = f"https://downsub.com{link}"
        elif not link.startswith('http'):
            link = f"https://downsub.com/{link}"

        response = session.get(link, timeout=30)
        logger.info(f"ä¸‹è½½å“åº”: {response.status_code}")

        if response.status_code == 200:
            content = response.text

            # æ£€æŸ¥æ˜¯å¦æ˜¯å­—å¹•å†…å®¹
            if (len(content) > 100 and
                ('webvtt' in content.lower() or
                 re.search(r'\d+:\d+:\d+', content) or
                 any(char in content for char in 'çš„æ˜¯åœ¨æœ‰ä¸ºäº†'))):  # ä¸­æ–‡å­—ç¬¦æ£€æµ‹

                logger.info("âœ… æˆåŠŸä¸‹è½½å­—å¹•å†…å®¹")

                # ä¿å­˜å­—å¹•
                filename = f"subtitle_downloaded_{int(time.time())}.txt"
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(content)

                logger.info(f"ğŸ’¾ å­—å¹•ä¿å­˜åˆ°: {filename}")
                logger.info(f"ğŸ“„ å†…å®¹é¢„è§ˆ: {content[:200]}...")

                return True

    except Exception as e:
        logger.error(f"ä¸‹è½½å¤±è´¥: {e}")

    return False


def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ å¼€å§‹å®Œæ•´çš„æµè§ˆå™¨æµç¨‹æ¨¡æ‹Ÿ...")

    result = simulate_full_browser_flow()

    if result:
        logger.info("ğŸ‰ æˆåŠŸè·å–å­—å¹•ï¼")
    else:
        logger.warning("âš ï¸ æœªèƒ½è·å–å­—å¹•ï¼Œä½†æ”¶é›†äº†æœ‰ç”¨ä¿¡æ¯")

    logger.info("\nğŸ“Š åˆ†ææ€»ç»“:")
    logger.info("1. å·²ä¿å­˜å„ç§å“åº”åˆ°æ–‡ä»¶ç”¨äºè¿›ä¸€æ­¥åˆ†æ")
    logger.info("2. æ”¶é›†äº†è¡¨å•å’Œ API è°ƒç”¨ä¿¡æ¯")
    logger.info("3. å¯ä»¥åŸºäºè¿™äº›ä¿¡æ¯å®Œå–„ DownSub é›†æˆ")


if __name__ == '__main__':
    main()